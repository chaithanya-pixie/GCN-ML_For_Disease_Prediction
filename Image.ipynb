{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d13b7815-dea8-4bc1-946a-9b5d8b44d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to:\n",
    "#Resize every image to 150x150.\n",
    "#Normalize pixel values between 0-1.\n",
    "#Label images (0 = NORMAL, 1 = PNEUMONIA).\n",
    "#Store everything inside NumPy arrays — ready for ML or DL models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "216d8879-367b-4928-ac25-4f99e4350727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder_path):\n",
    "        label_path = os.path.join(folder_path, label)\n",
    "        if os.path.isdir(label_path):\n",
    "            for image_filename in os.listdir(label_path):\n",
    "                image_path = os.path.join(label_path, image_filename)\n",
    "                img = cv2.imread(image_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, (150, 150))  # Resize all images to 150x150\n",
    "                    images.append(img)\n",
    "                    labels.append(0 if label == 'NORMAL' else 1)  # Normal=0, Pneumonia=1\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5966e177-ce32-4797-9f97-49c47659df44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: (5216, 150, 150, 3)\n",
      "Validation images: (16, 150, 150, 3)\n",
      "Test images: (624, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# Update these paths with your correct local path\n",
    "train_path = r'C:\\Users\\Chaithanya\\Downloads\\archive (2)\\chest_xray\\train'\n",
    "val_path = r'C:\\Users\\Chaithanya\\Downloads\\archive (2)\\chest_xray\\val'\n",
    "test_path = r'C:\\Users\\Chaithanya\\Downloads\\archive (2)\\chest_xray\\test'\n",
    "\n",
    "# Loading datasets\n",
    "X_train, y_train = load_images_from_folder(train_path)\n",
    "X_val, y_val = load_images_from_folder(val_path)\n",
    "X_test, y_test = load_images_from_folder(test_path)\n",
    "\n",
    "print(\"Train images:\", X_train.shape)\n",
    "print(\"Validation images:\", X_val.shape)\n",
    "print(\"Test images:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a68f835-2d6d-4be2-bae3-5c7a628ccb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # output:\n",
    "# Training images shape: (5216, 150, 150, 3) ✅ (5216 images, each 150x150 size, 3 color channels — RGB)\n",
    "# Training labels shape: (5216,) ✅(One label for each image)\n",
    "#Means — your image preprocessing is fully successful \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec285e4a-f622-4d54-afdb-236935aa6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML models like SVM, Random Forest, etc. cannot directly work with 3D images like (150,150,3).\n",
    "# We need numerical features to feed into ML models like SVM, KNN, Random Forest.)\n",
    "# Since we already resized images to 150x150 during preprocessing, we can flatten them into a 1D vector of numbers.\n",
    "# Each image = 150 × 150 × 3 = 67,500 features (pixels)\n",
    "# We will flatten the 3D image into a 1D vector.\n",
    "\n",
    "# flattening?\n",
    "# Traditional ML models (SVM, RF, KNN) expect tabular data (rows × columns)\n",
    "# Each row = 1 image, each column = 1 pixel value\n",
    "# Deep Learning (CNNs) can work with 3D images, but ML models cannot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fde2e1ce-9f62-4e2a-8caf-10468d37c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Train shape: (5216, 67500)\n",
      "Flattened Validation shape: (16, 67500)\n",
      "Flattened Test shape: (624, 67500)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the images into 1D vectors\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(\"Flattened Train shape:\", X_train_flat.shape)\n",
    "print(\"Flattened Validation shape:\", X_val_flat.shape)\n",
    "print(\"Flattened Test shape:\", X_test_flat.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4720f907-f2c9-4c73-89a2-c754b5ac8a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision: How many of the predicted positive cases were actually positive.\n",
    "# Recall: How many of the actual positive cases were correctly identified.\n",
    "# F1-Score: The harmonic mean of precision and recall, giving a balance between the two.\n",
    "# Accuracy: The overall percentage of correctly classified images.\n",
    "# support:refers to the number of actual occurrences (samples) of each class in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e379bf0-6a9d-42c0-bcc2-0bc18e29a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Traditional Machine Learning Models\n",
    "# Training SVM with the training data.\n",
    "# Predicting on the validation and test sets.\n",
    "# Evaluating the performance (accuracy, precision, recall, F1-score).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c96af36d-07f5-4222-9f2c-7aca5cb4d2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy: 0.81\n",
      "\n",
      "Classification Report (Validation):\n",
      "Class      Precision  Recall     F1-Score   Support   \n",
      "0          1.00       0.62       0.77       8         \n",
      "1          0.73       1.00       0.84       8         \n",
      "\n",
      "Test Accuracy: 0.75\n",
      "\n",
      "Classification Report (Test):\n",
      "Class      Precision  Recall     F1-Score   Support   \n",
      "0          0.97       0.35       0.52       234       \n",
      "1          0.72       0.99       0.83       390       \n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Flattening image data (already done in your previous steps)\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)  # Flatten images into 1D vectors for training\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)    # Flatten images into 1D vectors for testing\n",
    "X_val_flat = X_val.reshape(X_val.shape[0], -1)       # Flatten images into 1D vectors for validation\n",
    "\n",
    "# SVM Model training\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_flat, y_train)  # Train the model with flattened images and labels\n",
    "\n",
    "# Make predictions\n",
    "y_val_pred = svm_model.predict(X_val_flat)  # Predict labels for the validation set\n",
    "y_test_pred = svm_model.predict(X_test_flat)  # Predict labels for the test set\n",
    "\n",
    "# Function to print compact classification report\n",
    "def print_compact_classification_report(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    \n",
    "    print(f\"{'Class':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
    "    for class_label in [0, 1]:\n",
    "        class_report = report[str(class_label)]\n",
    "        print(f\"{class_label:<10} {class_report['precision']:<10.2f} {class_report['recall']:<10.2f} {class_report['f1-score']:<10.2f} {int(class_report['support']):<10}\")\n",
    "\n",
    "# Validation Accuracy\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy:.2f}\")\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print_compact_classification_report(y_val, y_val_pred)\n",
    "\n",
    "# Test Accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print_compact_classification_report(y_test, y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f586ca56-e42c-40c9-a2aa-7b95465ad731",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Support Vector Machine (SVM):\n",
    "# Validation Accuracy: 81.25%\n",
    "# Test Accuracy: 75.32%\n",
    "# Key Insights:\n",
    "# The SVM model has high precision and recall for class 1 (pneumonia), meaning it's good at identifying pneumonia cases.\n",
    "# For class 0 (normal), the model shows relatively poor recall, meaning it misses many normal cases.\n",
    "# Balanced performance overall, especially with a higher F1 score for class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83671af7-78a7-42b1-b771-e5dcfb896831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Accuracy (RF): 0.62\n",
      "\n",
      "Classification Report (Validation - RF):\n",
      "Class     Precision Recall    F1-Score  Support   \n",
      "0         1.00      0.25      0.40      8.0       \n",
      "1         0.57      1.00      0.73      8.0       \n",
      "\n",
      "Test Accuracy (RF): 0.76\n",
      "\n",
      "Classification Report (Test - RF):\n",
      "Class     Precision Recall    F1-Score  Support   \n",
      "0         0.97      0.38      0.54      234.0     \n",
      "1         0.73      0.99      0.84      390.0     \n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Function to print classification report in a compact format\n",
    "def print_compact_classification_report(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    print(f\"{'Class':<10}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}{'Support':<10}\")\n",
    "    for class_label in sorted(report.keys()):\n",
    "        if class_label in ['0', '1']:  # Only print actual class results, skip 'accuracy', 'macro avg', etc.\n",
    "            class_report = report[class_label]\n",
    "            print(f\"{class_label:<10}{class_report['precision']:<10.2f}{class_report['recall']:<10.2f}{class_report['f1-score']:<10.2f}{class_report['support']:<10}\")\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train_flat, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_rf = rf_model.predict(X_val_flat)\n",
    "\n",
    "# Evaluate the model - Validation\n",
    "val_accuracy_rf = accuracy_score(y_val, y_val_pred_rf)\n",
    "print(f\"\\nValidation Accuracy (RF): {val_accuracy_rf:.2f}\")\n",
    "print(\"\\nClassification Report (Validation - RF):\")\n",
    "print_compact_classification_report(y_val, y_val_pred_rf)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred_rf = rf_model.predict(X_test_flat)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "print(f\"\\nTest Accuracy (RF): {test_accuracy_rf:.2f}\")\n",
    "print(\"\\nClassification Report (Test - RF):\")\n",
    "print_compact_classification_report(y_test, y_test_pred_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb764a-d5d7-43c8-9c97-9e59dff7d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Accuracy: 62.5%\n",
    "# Test Accuracy: 76.03%\n",
    "# Performs very well in detecting pneumonia (class 1) with high recall.\n",
    "# Struggles to correctly identify normal cases (class 0) — high precision but poor recall.\n",
    "# Better overall test performance than SVM but with imbalanced class predictions.\n",
    "# Main issue: Many normal cases are misclassified as pneumonia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "17fd6b02-c222-4e20-b9b7-e65fd7db76ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (KNN): 0.50\n",
      "\n",
      "Classification Report (Validation - KNN):\n",
      "Class     Precision Recall    F1-Score  Support   \n",
      "0         0.00      0.00      0.00      8         \n",
      "1         0.50      1.00      0.67      8         \n",
      "\n",
      "Test Accuracy (KNN): 0.74\n",
      "\n",
      "Classification Report (Test - KNN):\n",
      "Class     Precision Recall    F1-Score  Support   \n",
      "0         0.99      0.30      0.46      234       \n",
      "1         0.70      1.00      0.83      390       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chaithanya\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Chaithanya\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Chaithanya\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize KNN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Train the model\n",
    "knn_model.fit(X_train_flat, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_knn = knn_model.predict(X_val_flat)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred_knn = knn_model.predict(X_test_flat)\n",
    "\n",
    "# Function to print compact classification report\n",
    "def print_compact_classification_report(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    print(f\"{'Class':<10}{'Precision':<10}{'Recall':<10}{'F1-Score':<10}{'Support':<10}\")\n",
    "    for class_label in sorted(report.keys()):\n",
    "        if class_label in ['0', '1']:  # Only for classes 0 and 1\n",
    "            class_report = report[class_label]\n",
    "            print(f\"{class_label:<10}{class_report['precision']:<10.2f}{class_report['recall']:<10.2f}{class_report['f1-score']:<10.2f}{int(class_report['support']):<10}\")\n",
    "\n",
    "# Validation Accuracy\n",
    "val_accuracy_knn = accuracy_score(y_val, y_val_pred_knn)\n",
    "print(f\"Validation Accuracy (KNN): {val_accuracy_knn:.2f}\")\n",
    "\n",
    "# Classification Report for Validation\n",
    "print(\"\\nClassification Report (Validation - KNN):\")\n",
    "print_compact_classification_report(y_val, y_val_pred_knn)\n",
    "\n",
    "# Test Accuracy\n",
    "test_accuracy_knn = accuracy_score(y_test, y_test_pred_knn)\n",
    "print(f\"\\nTest Accuracy (KNN): {test_accuracy_knn:.2f}\")\n",
    "\n",
    "# Classification Report for Test\n",
    "print(\"\\nClassification Report (Test - KNN):\")\n",
    "print_compact_classification_report(y_test, y_test_pred_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ca3e3-3b9d-4e29-a331-35c642174ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Accuracy: 50%\n",
    "# Test Accuracy: 74%\n",
    "# Good at detecting pneumonia (Class 1) — high recall.\n",
    "# Very poor at detecting normal cases (Class 0) — low precision and recall.\n",
    "# Strong bias towards predicting pneumonia.\n",
    "# Misclassifies many healthy patients as pneumonia.\n",
    "# Overall: Decent test accuracy but imbalanced performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
